# <center>K-Means聚类</center>

常见的聚类方法有：K-Means聚类、层次聚类、密度聚类、谱聚类和高斯混合聚类等。

## 1、K-Means聚类

### 1.1、K-Means聚类过程

​		K-Means 算法是一种无监督的聚类算法。K-Means核心思想是：给定的样本数据集，根据样本点之间的距离大小，把数据集划分成 K 个簇，并让簇内的样本点尽量距离近，而不同簇之间的距离极可能的远。



### 1.2、K-Means聚类过程

​		K-Means聚类过程有四个步骤，即聚类簇数K值的选择、K个聚类中心店的初始值选择、距离度量方式、损失函数的选择。

（1）聚类簇数 K 值的选择

​		聚类簇数 K 值的选择是一个比较难处理的地方，它会对 K-Means 算法的最终结果起到关键作用，在实际中，一般并不知道要把样本数据分为几类。K-Means 算法在处理这个问题时注意依靠人工试探或者超参数探索的形式来确定。

（2）K 个聚类中心点初始值选择

​		K 个聚类中心点的初始值选择会直接的影响算法需要更新迭代的次数。K-Means 算法是先随机从样本点中选择 K 个点作为聚类中心点的初始值。<font color='red'>（不是最好的方式，有改进方法）</font>		

（3）距离度量方式

​		距离的计算有很多方式，如欧式距离、汉明距离等，使用较多的是欧式距离。假设数据样本点的特征维度是 N ，那么，两个 N 维向量$X=(x_{11} , x_{12}, ... , x_{1n})$ 和 $Y=(y_{11} , y_{12}, ... , y_{1n})$之间的欧式距离为：
$$
d = \sqrt{\sum\limits_{i=1}^N(x_{1i} - y_{1i})}
$$


（4）损失函数的选择

​		判断聚类迭代是否趋于稳定需要根据聚类损失函数的变化情况来判断。聚类算法的损失函数的各个簇中样本向量对应簇均值向量的均方误差。假设，数据样本点为$X=(x_{1} , x_{2}, ... , x_{n})$ ，需要被聚类成 K 个簇 $C=(c_{1} , c_{2}, ... , c_{n})$，则各个簇内样本点的均值向量为：
$$
\mu_k = \frac{1}{N_k}\sum\limits_{x_i \in C_k}x_i
$$
​	其中，$N_k$为簇$C_k$中包含的样本点数目，所有簇的总均方误差为：
$$
E = \sum\limits_{k=1}^K \sum\limits_{x_i \in C_k}||x_i - \mu_k ||^2
$$
​	所以，迭代求解 K-Means 算法的目标就是最小化损失函数，即均方误差。

### 1.3、K-Means算法步骤

输入：待聚类的数据集样本 $X=(x_{1} , x_{2}, ... , x_{n})$ ，聚类簇数K（即要分类数），最大迭代次数 n 。

输出：聚类后的数据集 $C=(c_{1} , c_{2}, ... , c_{n})$ 。

实现步骤：

1. 从数据集 $X$ 中随机选择 K 个聚类中心，设对应的向量为 $\mu=(\mu_{1} , \mu_{2}, ... , \mu_{k})$ .
2. 计算各个样本点到 K 个聚类中心的距离 $||x_i - \mu_k ||^2_2$ ，并把各个样本点归入离其距离最近的类别中.
3. 重新进行迭代运算，计算得到的 K 个类别的中心向量，并更新为新的聚类中心，计算方法为：

$$
\mu_k^{\ `} = \frac{1}{N_k}\sum\limits_{x_i \in C_k}x_i
$$

4. 重复第2和第3步计算，直到满足最大迭代次数n或所有类别的中心点不在发生变化，这时，得到聚类好的输出数据集 $C=(c_{1} , c_{2}, ... , c_{n})$.



